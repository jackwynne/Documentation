{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2773ce14-5fe9-4705-96b6-7c46f4f70872",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Getting Started with Azure Databricks - A Census Data Example\n",
    "\n",
    "This notebook is a simple example of working with data in Azure Databricks.\n",
    "\n",
    "If you are reading this on the wiki, you can find the working Notebook in the Azure Databricks environment at the following path: [/Shared/Getting Started with Azure Databricks - A Census Data Example](https://adb-5195694350474952.12.azuredatabricks.net/?o=5195694350474952#notebook/3876325875947739)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d4fabe8-011b-42d8-a3da-3c7baaea5345",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Explore the ADLS folders\n",
    "\n",
    "You can explore filesystems directly through Notebooks by using the [`dbutils.fs` client](https://docs.microsoft.com/en-us/azure/databricks/dev-tools/databricks-utils).\n",
    "\n",
    "Below we exaplore the CSVs for the night population census:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e56c7e9-1cbe-4ce7-84a8-51cecb9e98d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(\"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "450b8ec9-f8ec-4436-a314-ad6eece66d83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(\"abfss://sandbox@aueprddlsnzlh001.dfs.core.windows.net/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87024c30-9bc3-4304-a149-24bdab6e7491",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af6e09c0-1af2-46fb-98ac-ca1d1ff5f9df",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you can see above, the ADLS Gen2 container for the project (`abfss://sandbox@aueprddlsnzlh001.dfs.core.windows.net/`) is set as the default filesystem for clusters associated with that project (in this case `sandbox`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebf1e426-17a8-47a3-b99f-00903955923d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Read in the CSVs and explore the data\n",
    "\n",
    "We can read the source CSVs into Spark as DataFrames and explore the data.\n",
    "\n",
    "We use the [DataFrame API](https://spark.apache.org/docs/3.0.0/sql-getting-started.html) to transform the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e86f303-9cf5-4d69-8be7-794f42123bd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e010f434-e68f-4e4b-bfb0-c90c4b381ab9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1695e006-6002-4b7b-8b34-93ab674172c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The datatypes and headers look incorrect: all the datatypes are strings and the headers have not been read. We can fix this by passing in [reader options](https://spark.apache.org/docs/2.3.0/sql-programming-guide.html#manually-specifying-options)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc570d6f-f6db-4e31-9bc0-e814c9f31e93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ff267ab-feb4-4766-9e60-05e91c4e695d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40c44a49-918f-43c7-8d30-12580d6f73c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5738f98f-f6d6-401d-9086-23417ffc4e2b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's take a look at a couple of the dimension tables too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d1b6b40-1d87-4c97-bf51-a93d6cccfdeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookupAge8317.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d83303ce-d77c-4201-bb34-26f91c842738",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f406550-fcbe-4752-b361-387d8822eb96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookupEthnic8317.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "252c5c77-d4ee-4445-9ac0-54459afcb77e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24bb2248-1ebc-4456-ba41-9b06e1ffb284",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Observation: the dimension tables seem to have a consistent schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4063b5b9-3a42-4dbe-8ce9-afcb588f261d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Denormalise the source tables\n",
    "Since we are using Apache Spark we want to limit joins the number of joins/data transfer between nodes. Filters and aggregations suit the architecture better, and data will be stored in columnar-compressed files therefore it would make sense to denormalise the data.\n",
    "\n",
    "Let's join all the data into one large DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "276128be-fc96-465b-bc71-8ce37c3bde55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "denorm_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\")\n",
    "for dim in [\"Age\", \"Area\", \"Ethnic\", \"Sex\", \"Year\"]:\n",
    "  dim_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(f\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookup{dim}8317.csv\")\n",
    "  denorm_df = denorm_df.join(dim_df, col(dim) == col(\"Code\")).drop(\"Code\", dim).withColumnRenamed(\"Description\", dim).withColumnRenamed(\"SortOrder\", f\"{dim}SortOrder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03f068c9-9cf6-4a95-826b-4d7a5433b9e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(denorm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1352d4fa-2acf-48fb-ac60-14562e689bc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d912760f-73a7-42b4-8c00-aceed38f23e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Investigate duplicates 🕵️‍♀️\n",
    "\n",
    ">Pre-join count: 34959673\n",
    "\n",
    ">Post-join count: 48585735\n",
    "\n",
    "The counts look incorrect: the dimension joins are only lookups and should not produce additional rows.\n",
    "\n",
    "Let's look into why this has happened.\n",
    "\n",
    "Hypothesis: the code column shouldn't be inferred as an integer column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "653ff4ed-eec9-4f71-a150-a3046e7a763d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "With schema inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "817bdbcf-1f48-4bdb-884e-6f8e8792683a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookupAge8317.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40e0d3da-9631-4502-875d-c61621a9be95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26524f19-297f-4718-97f9-3fed280fe704",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Without schema inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9886782c-b124-47ac-ac67-db320407d841",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookupAge8317.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e661f23c-9fec-4dec-baab-c2da4f722831",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36149d20-1e58-4246-9249-fac05bd65c5e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Schema inference shot us in the foot! 🦶🔫\n",
    "\n",
    "Try again without infering any datatypes (we can manually cast later!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edbdb41f-f273-449b-8ffc-a705347c2306",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "denorm_df = spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\")\n",
    "for dim in [\"Age\", \"Area\", \"Ethnic\", \"Sex\", \"Year\"]:\n",
    "  dim_df = spark.read.option(\"header\", True).csv(f\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookup{dim}8317.csv\")\n",
    "  denorm_df = denorm_df.join(dim_df, col(dim) == col(\"Code\")).drop(\"Code\", dim).withColumnRenamed(\"Description\", dim).withColumnRenamed(\"SortOrder\", f\"{dim}SortOrder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3b0a57-af97-4b5c-901b-ab3350eb858a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1263f4f-471b-4800-80e0-a5503e892bf9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    ">Pre-join count: 34959673\n",
    "\n",
    ">Post-join count: 34885323\n",
    "\n",
    "Closer, but it looks like we lost a few rows this time.\n",
    "\n",
    "Let's try a left join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf4debed-3553-4b2d-aaca-9c908e6ae5a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "denorm_df = spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\")\n",
    "for dim in [\"Age\", \"Area\", \"Ethnic\", \"Sex\", \"Year\"]:\n",
    "  dim_df = spark.read.option(\"header\", True).csv(f\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookup{dim}8317.csv\")\n",
    "  denorm_df = denorm_df.join(dim_df, col(dim) == col(\"Code\"), how=\"left\").drop(\"Code\", dim).withColumnRenamed(\"Description\", dim).withColumnRenamed(\"SortOrder\", f\"{dim}SortOrder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f038734-4b2d-4a36-bfd6-99b82b45b584",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "422dcb74-04aa-424f-9f64-2408f787dc29",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Bingo! The counts match. However, this implies something doesn't join to it's dimension lookup.\n",
    "\n",
    "Let's hunt for nulls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b14b7b23-e01d-4ac1-a421-195f3360d192",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(denorm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d556964-ac25-40be-b3bc-7a1fe8dfe6e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df_nulls = denorm_df.filter(col(\"Age\").isNull() | col(\"Area\").isNull() | col(\"Ethnic\").isNull() | col(\"Sex\").isNull() | col(\"Year\").isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc0f0021-c74d-4d32-969f-2cd78feec5e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df_nulls.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18ccf108-23a9-43a6-9238-9a5f14071d0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(denorm_df_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fca2fe9-af70-4a61-8281-b5571dfc1675",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df_nulls.filter(col(\"Age\") == \"Median age\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "227f3a67-d09f-4bd3-9cd7-8fb2092cd211",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "All the duplicates come from the median age category.\n",
    "\n",
    "We should take some time to understand our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "deb3dec0-3090-40d7-bcd2-7557674674d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookupAge8317.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f73f09e-5f96-43fb-b32f-866a87c864cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's filter the fact table by the top two codes as they look odd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54fa3b91-cf89-40b3-8dc9-fc25ae172822",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df = spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\").filter(col(\"Age\").isin([\"999999\", \"888\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3097ac4-6f0c-4a4b-a24c-0e96b4385ed2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef324941-3234-4406-baf5-636aa2feabcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df.filter(col(\"Age\") == \"888\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "124c5724-170f-4d13-8d16-7859f6da605e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "It's getting a little hard to trace columns and codes, so let's denormalise whilst retaining the code columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1be3e2f4-51e7-4e82-a5f8-bdc4cf7a030f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "denorm_df = spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\")\n",
    "for dim in [\"Age\", \"Area\", \"Ethnic\", \"Sex\", \"Year\"]:\n",
    "  dim_df = spark.read.option(\"header\", True).csv(f\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookup{dim}8317.csv\")\n",
    "  denorm_df = denorm_df.join(dim_df, col(dim) == col(\"Code\"), how=\"left\").drop(\"Code\").withColumnRenamed(dim, f\"{dim}Code\").withColumnRenamed(\"Description\", dim).withColumnRenamed(\"SortOrder\", f\"{dim}SortOrder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "540db7af-6ff6-4e70-81d7-21ac83065a99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df_nulls = denorm_df.filter(col(\"Age\").isNull() | col(\"Area\").isNull() | col(\"Ethnic\").isNull() | col(\"Sex\").isNull() | col(\"Year\").isNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "664de80d-9106-4764-adfa-6741503959b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(denorm_df_nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dc02ab6-6eda-4141-bc4d-c707f162b162",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The area code doesn't match.\n",
    "\n",
    "Let's dig deeper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dd1ee4c-379e-4c45-950e-e262029ff395",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookupArea8317.csv\").filter(col(\"Code\").isin([\"1\", \"01\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4998e6fc-edec-4a7d-a0d1-f91ac06c52e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Seems like some of the area codes don't lookup correctly.\n",
    "\n",
    "Let's also look at sex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88fc8de7-df25-4b7b-97a0-9b8bce1410dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(denorm_df_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a8b815c-7e31-48ea-806e-bbb89e0f3414",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookupSex8317.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc14a35e-8e3d-4ea2-bfaa-12ba4b41f2d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Conclusion: the data looks a little odd and needs investigating further. For now, let's continue with the denormalisation as we can fix these issues later by keeping the raw CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d28975af-f494-4026-888e-e06fc3762da6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating output files, Hive databases and tables\n",
    "\n",
    "When writing out DataFrames, we can write them out in [various formats](https://spark.apache.org/docs/3.0.0/sql-data-sources.html), and optionally add a Hive table over these files.\n",
    "\n",
    "Hive tables are 'virtual' SQL tables over data stored (in this case stored on ADLS).\n",
    "We can use either:\n",
    "* External tables: create tables over existing data\n",
    "* Hive-managed tables: create tables and data at the same time\n",
    "\n",
    "Both options produce the same end, and are only subtly different.\n",
    "\n",
    "When we create Hive tables, we are really writing out the DataFrame to ADLS and adding a schema and file path reference to Hive.\n",
    "\n",
    "Let's create a Hive database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "480b3d62-8254-451b-b720-b7b4208be360",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create database if not exists sandbox;\n",
    "use sandbox;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "329cd297-18eb-4638-85b5-2753691e135a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now, let's create our final DataFrame we would like to write out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "97d880ca-0610-42db-b487-1cc6009dc8d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df = spark.read.option(\"header\", True).csv(\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/Data8317.csv\")\n",
    "for dim in [\"Age\", \"Area\", \"Ethnic\", \"Sex\", \"Year\"]:\n",
    "  dim_df = spark.read.option(\"header\", True).csv(f\"/data/raw/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/DimenLookup{dim}8317.csv\")\n",
    "  denorm_df = denorm_df.join(dim_df, col(dim) == col(\"Code\"), how=\"left\").drop(\"Code\").withColumnRenamed(dim, f\"{dim}Code\").withColumnRenamed(\"Description\", dim).withColumnRenamed(\"SortOrder\", f\"{dim}SortOrder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43ce5687-f2ac-405c-bc59-b75d8873032f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can write the files out directly as Parquet (with no Hive table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d4366be-cebf-4970-ab51-efe834b04d9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df.write.mode(\"overwrite\").parquet(\"/data/derived/stats_nz_census/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz_denorm/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b52fcc19-4f7f-46e7-833c-97890ea6b94a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Or we can write the files out (by default in Parquet) and create a Hive table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e43d136f-f99d-4684-a068-18f9eef9f8c0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "denorm_df.write.mode(\"overwrite\").saveAsTable(\"sandbox.age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1895c477-58df-4048-b866-56e5f10f28ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "We can now query the Hive table using SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea47a35f-e93f-48c4-b60f-1c893ecda71f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from sandbox.age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00eaacca-9498-464d-af9d-bd68ef972894",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "And we have three ways of opening the Hive table as a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "556d680c-304c-4fd4-a4f5-09ac17c32357",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "df_s = spark.sql(\"select * from sandbox.age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz\")\n",
    "df_h = spark.read.table(\"sandbox.age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz\")\n",
    "df_p = spark.read.parquet(\"/tables/sandbox.db/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "449c9bf5-b235-4d23-ad0c-d530f7696363",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The underlying Hive-backed table metadata and data files look like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "095151bb-48bc-4d2e-b96c-695651a6354e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "describe formatted sandbox.age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5761457d-a2d5-4848-91bd-fe1f531c9e0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(dbutils.fs.ls(\"/tables/sandbox.db/age_and_sex_by_ethnic_group_census_night_population_counts_2006_2013_2018_nz/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96ec5feb-ad11-4803-9ce9-43f7e3019dd6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "We now have a virtual Hive table we can query using SQL, and we can create a DataFrame using an SQL query, a reference to the Hive table or by reading the underlying Parquet files.\n",
    "\n",
    "And since the underlying files are Snappy-compressed Parquet, the underlying filesize has gone from 800Mb CSVs (100Mb compressed) to 50Mb Parquet files (even though we denormalised!)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Getting Started with Azure Databricks - A Census Data Example",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
